---
title: "Meta-Analysis and Network Meta-Analysis"
description: >
  Comprehensive guide to pairwise meta-analysis, indirect comparison, network
  meta-analysis, and Bayesian meta-analysis using pharmhand for HTA submissions.
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Meta-Analysis and Network Meta-Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)
```

```{r setup}
library(pharmhand)
```

## Introduction
pharmhand provides comprehensive functions for meta-analysis and network
meta-analysis (NMA), supporting German HTA requirements (G-BA/IQWiG).

## Pairwise Meta-Analysis

### Basic Meta-Analysis

```{r meta-basic}
# Five studies with hazard ratios
yi <- log(c(0.75, 0.82, 0.68, 0.91, 0.77))
sei <- c(0.12, 0.15, 0.18, 0.14, 0.11)

result <- meta_analysis(
  yi = yi,
  sei = sei,
  study_labels = paste("Study", 1:5),
  effect_measure = "hr",
  model = "random",
  method = "REML",
  knapp_hartung = TRUE
)

result@estimate
result@ci
result@heterogeneity$I2
```

### Heterogeneity Assessment

```{r heterogeneity}
het <- calculate_heterogeneity(yi, sei, method = "REML")
het$Q
het$I2
het$tau2
het$interpretation
```

### Leave-One-Out Sensitivity Analysis

```{r loo}
loo <- leave_one_out(result)
loo$results[, c("excluded_study", "estimate_display", "I2")]
loo$influential_studies
```

### Forest Plot

```{r forest, fig.alt="Meta-analysis forest plot"}
plot <- create_meta_forest_plot(result, title = "Treatment Effect (HR)")
plot@plot
```

### Funnel Plot and Publication Bias

```{r funnel, fig.alt="Funnel plot"}
funnel <- create_funnel_plot(result, title = "Funnel Plot")
funnel@plot
```

```{r egger}
egger <- eggers_test(yi = yi, sei = sei)
egger$p_value
egger$interpretation
```

### Trim-and-Fill

```{r trimfill}
tf <- trim_and_fill(result)
tf$n_imputed
tf$interpretation
```

## Indirect Comparison

```{r indirect}
# Bucher method: A vs B via common comparator C
indirect <- indirect_comparison(
  effect_ab = log(0.75),  # A vs C
  se_ab = 0.12,
  effect_bc = log(0.85),  # B vs C
  se_bc = 0.10,
  effect_measure = "hr",
  label_a = "Drug A",
  label_b = "Placebo",
  label_c = "Drug B"
)
indirect@estimate
indirect@ci
```

## Network Meta-Analysis

### Basic NMA

```{r nma}
nma_data <- data.frame(
  study = c("S1", "S2", "S3", "S4"),
  treat1 = c("A", "B", "A", "B"),
  treat2 = c("B", "C", "C", "D"),
  effect = log(c(0.75, 0.90, 0.80, 0.85)),
  se = c(0.12, 0.15, 0.18, 0.14)
)

nma <- network_meta(nma_data, effect_measure = "hr")
nma$comparisons
```

### Network Geometry Plot

```{r network-plot, fig.alt="Network geometry plot"}
net_plot <- create_network_plot(nma, title = "Treatment Network")
net_plot@plot
```

### SUCRA Rankings

```{r sucra}
sucra <- calculate_sucra(nma)
sucra$ranking
sucra$interpretation
```

### League Table

```{r league}
league <- create_league_table(nma)
league@data
```

### Transitivity Assessment

```{r transitivity}
chars <- data.frame(
  study_id = c("S1", "S1", "S2", "S2", "S3", "S3", "S4", "S4"),
  treatment = c("A", "B", "B", "C", "A", "C", "B", "D"),
  mean_age = c(55, 55, 58, 58, 52, 52, 60, 60),
  pct_male = c(60, 60, 65, 65, 55, 55, 70, 70)
)

transit <- assess_transitivity(
  study_characteristics = chars,
  char_vars = c("mean_age", "pct_male"),
  continuous_vars = c("mean_age", "pct_male")
)
transit$overall_assessment
```

## Consistency Assessment

A key assumption in network meta-analysis is consistency between direct and
indirect evidence. pharmhand provides tools to assess this assumption.

### Comparing Direct and Indirect Evidence

When both direct (head-to-head) and indirect evidence exist for a comparison,
we can test whether they agree:

```{r consistency}
# Suppose we have direct evidence for A vs B from a head-to-head trial
direct <- list(
  estimate = log(0.78),
  se = 0.14
)

# And indirect evidence via common comparator C
indirect <- indirect_comparison(
  effect_ab = log(0.75),  # A vs C
  se_ab = 0.12,
  effect_bc = log(0.96),  # B vs C
  se_bc = 0.11,
  effect_measure = "hr",
  label_a = "A",
  label_b = "C",
  label_c = "B"
)

# Compare direct and indirect evidence
consistency <- compare_direct_indirect(
  direct_result = direct,
  indirect_result = indirect,
  effect_measure = "hr"
)

consistency$direct_estimate
consistency$indirect_estimate
consistency$inconsistency_p
consistency$is_consistent
```

A non-significant p-value (p > 0.05) suggests the direct and indirect evidence
are consistent, supporting the validity of the indirect comparison.

### Node-Splitting Analysis

For network meta-analyses, node-splitting separates direct and indirect
evidence for each comparison to identify potential inconsistencies:

```{r node-split}
# Node-splitting analysis on our NMA
ns <- node_splitting(nma)
ns$results
ns$note
```

Node-splitting helps identify specific comparisons where direct and indirect
evidence may disagree, which could indicate violations of the transitivity
assumption.

## Bayesian Meta-Analysis

For researchers preferring Bayesian inference, pharmhand provides an interface
to Bayesian meta-analysis using the brms package. This allows specification of
informative priors and provides full posterior distributions.

### Basic Bayesian Meta-Analysis

```{r bayesian, eval=FALSE}
# Bayesian random-effects meta-analysis
# Requires: install.packages("brms")
bayes_result <- bayesian_meta_analysis(
  yi = yi,
  sei = sei,
  study_labels = paste("Study", 1:5),
  effect_measure = "hr",
  prior_mu = list(mean = 0, sd = 10),
  prior_tau = list(type = "half_cauchy", scale = 0.5),
  chains = 4,
  iter = 4000,
  adapt_delta = 0.95,
  max_treedepth = 12,
  seed = 12345
)

# Posterior summary statistics
bayes_result$posterior_mean      # Mean of posterior distribution
bayes_result$posterior_median    # Median of posterior distribution
bayes_result$ci_95               # 95% credible interval
bayes_result$prob_benefit        # P(HR < 1)
bayes_result$prob_superior       # P(HR < 0.9)
```

### Convergence Diagnostics

The function now automatically reports convergence diagnostics to ensure reliable results:

```{r convergence, eval=FALSE}
# Access convergence diagnostics
bayes_result$convergence_diagnostics

# Check individual metrics
bayes_result$convergence_diagnostics$max_rhat      # Should be <= 1.01
bayes_result$convergence_diagnostics$min_bulk_ess # Should be >= 400
bayes_result$convergence_diagnostics$min_tail_ess # Should be >= 400
bayes_result$convergence_diagnostics$divergent_transitions # Should be 0
```

Warnings are automatically issued when convergence issues are detected. To improve convergence:

- Increase `adapt_delta` parameter (try 0.99 or 0.999)
- Increase `iter` for more samples
- Use more informative priors

### Predictive Checks

#### Posterior Predictive Checks

Assess model fit to the observed data:

```{r pp-check, eval=FALSE}
# Enable posterior predictive checks
bayes_result <- bayesian_meta_analysis(
  yi = yi,
  sei = sei,
  effect_measure = "hr",
  posterior_predictive = TRUE,
  pp_check_type = "dens_overlay",
  pp_ndraws = 100
)

# View posterior predictive plot
bayes_result$pp_check_plot

# Check Bayesian p-value (should be around 0.5 for good fit)
bayes_result$posterior_predictive$bayes_p_value
```

#### Prior Predictive Checks

Evaluate prior reasonableness before seeing data:

```{r prior-check, eval=FALSE}
# Fit with prior-only
bayes_result <- bayesian_meta_analysis(
  yi = yi,
  sei = sei,
  effect_measure = "hr",
  prior_predictive = TRUE
)

# View prior distribution
bayes_result$prior_predictive$summary
```

### Trace Plots

Visualize MCMC chain convergence:

```{r trace-plot, eval=FALSE}
# Create combined trace plots
trace_plot <- create_bayesian_trace_plots(bayes_result)
print(trace_plot)

# Create individual parameter plots
trace_plots <- create_bayesian_trace_plots(
  bayes_result,
  parameters = c("b_Intercept", "sd_study__Intercept"),
  combine_plots = FALSE
)
print(trace_plots$b_Intercept)
```

Good convergence shows:
- Well-mixed chains (no drift or stickiness)
- Similar distributions across chains
- Rapid autocorrelation decay

### Prior Sensitivity Analysis

Test how results change with different prior specifications:

```{r sensitivity, eval=FALSE}
# Run sensitivity analysis with default scenarios
sensitivity <- prior_sensitivity_analysis(
  yi = yi,
  sei = sei,
  effect_measure = "hr",
  chains = 2,
  iter = 2000
)

# Compare estimates across priors
sensitivity$comparison

# View robustness summary
sensitivity$sensitivity_summary$robustness_interpretation
```

Or specify custom prior scenarios:

```{r sensitivity-custom, eval=FALSE}
custom_scenarios <- list(
  skeptical = list(
    prior_mu = list(mean = 0, sd = 0.5),
    prior_tau = list(type = "half_cauchy", scale = 0.3)
  ),
  optimistic = list(
    prior_mu = list(mean = -0.5, sd = 1),
    prior_tau = list(type = "half_cauchy", scale = 0.2)
  )
)

sensitivity <- prior_sensitivity_analysis(
  yi = yi,
  sei = sei,
  effect_measure = "hr",
  prior_scenarios = custom_scenarios
)
```

### IQWiG-Compliant Reporting

Format results for German HTA submissions:

```{r iqwig-format, eval=FALSE}
# Format for IQWiG submission
formatted <- format_bayesian_result_iqwig(
  bayes_result,
  locale = "de"  # German locale
)

# View formatted components
formatted$estimate      # "0.790"
formatted$ci           # "[0.712; 0.877]"
formatted$probability   # "P(HR < 1) = 98.5%"
formatted$interpretation # Complete interpretation

# Export full formatted text
formatted$full_text
```

Create IQWiG-compliant forest plots:

```{r iqwig-forest, eval=FALSE}
# Create IQWiG-formatted forest plot
study_data <- data.frame(
  yi = yi,
  sei = sei,
  study_labels = paste("Study", 1:5)
)

forest_iqwig <- create_bayesian_forest_plot_iqwig(
  bayes_result,
  study_data = study_data,
  locale = "de",
  title = "Behandlungseffekt (HR)"
)
print(forest_iqwig)
```

**Note:** Bayesian meta-analysis requires the `brms` package and a working
Stan installation. Install with `install.packages("brms")`. For users without
brms, the frequentist `meta_analysis()` function provides an alternative.

Advantages of the Bayesian approach include:

- Natural interpretation of credible intervals as probability statements
- Ability to incorporate prior knowledge
- Full posterior distributions for all parameters
- Better handling of small sample sizes

## Summary

pharmhand provides a complete toolkit for evidence synthesis:

| Function | Purpose |
|----------|---------|
| `meta_analysis()` | Fixed/random-effects meta-analysis |
| `calculate_heterogeneity()` | Q, I², τ² statistics |
| `leave_one_out()` | Sensitivity analysis |
| `create_meta_forest_plot()` | Forest plot visualization |
| `create_funnel_plot()` | Publication bias assessment |
| `eggers_test()` | Funnel asymmetry test |
| `trim_and_fill()` | Bias adjustment |
| `indirect_comparison()` | Bucher indirect comparison |
| `compare_direct_indirect()` | Test direct vs indirect consistency |
| `network_meta()` | Network meta-analysis |
| `create_network_plot()` | Network geometry |
| `calculate_sucra()` | Treatment rankings |
| `create_league_table()` | Pairwise comparisons |
| `assess_transitivity()` | Transitivity check |
| `node_splitting()` | NMA inconsistency testing |
| `bayesian_meta_analysis()` | Bayesian meta-analysis (via brms) |
| `create_bayesian_trace_plots()` | MCMC trace plot visualization |
| `prior_sensitivity_analysis()` | Prior sensitivity analysis |
| `format_bayesian_result_iqwig()` | IQWiG formatting for Bayesian results |
| `create_bayesian_forest_plot_iqwig()` | IQWiG-compliant forest plots |
